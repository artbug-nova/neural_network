# -*- coding: utf-8 -*-
"""neural_robot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-15q_L3NEvxOy1_E5sKV_sPUjaB9obOk
"""

import numpy as np
import pandas as pd
import tensorflow as tf

from keras.layers import Dense
from keras.models import Sequential
from keras.utils.vis_utils import plot_model

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from forwardKinematicsKuka import RV

"""### Датасет"""

data = pd.read_csv("https://github.com/artbug-nova/neural_network/raw/main/dataset.csv", delimiter=";")

"""### Анализ датасета"""

data.shape

data.head()

data.describe()

feature_columns = ["X", "Y", "Z"]
target_columns = ["Q0", "Q1", "Q2", "Q3", "Q4", "Q5"]

pca = PCA(n_components=3)
idx_subset = np.random.choice(data.shape[0], replace=False, size=10000)
data_subset = data.loc[idx_subset]

pca_result = pca.fit_transform(data_subset[feature_columns].values)

print("Explained variation per principal component: {}".format(pca.explained_variance_ratio_))

data_subset["pca1"] = pca_result[:,0]
data_subset["pca2"] = pca_result[:,1] 
data_subset["pca3"] = pca_result[:,2]

fig, axes = plt.subplots(figsize=(12, 8), ncols=3, nrows=2)

for q, ax in zip(target_columns, axes.flat):
    sns.scatterplot(
        x="pca1", y="pca2",
        hue=q,
        data=data_subset,
        palette=sns.color_palette("coolwarm", as_cmap=True), 
        alpha=0.3,
        ax=ax
    )

fig.tight_layout()

fig, axes = plt.subplots(figsize=(12, 8), ncols=3, nrows=2,
                         subplot_kw=dict(projection="3d"))

for q, ax in zip(target_columns, axes.flat):
    ax.scatter(
        xs=data_subset["pca1"], 
        ys=data_subset["pca2"], 
        zs=data_subset["pca3"], 
        c=data_subset[q],
    )

fig.tight_layout()

tsne = TSNE(n_components=2, perplexity=40, n_iter=300, learning_rate="auto", init="random")
tsne_results = tsne.fit_transform(data_subset)

data_subset["tsne1"] = tsne_results[:, 0]
data_subset["tsne2"] = tsne_results[:, 1]

fig, axes = plt.subplots(figsize=(12, 8), ncols=3, nrows=2)

for q, ax in zip(target_columns, axes.flat):
    sns.scatterplot(
        x="tsne1", y="tsne2",
        hue=q,
        data=data_subset,
        palette=sns.color_palette("coolwarm", as_cmap=True), 
        alpha=0.3,
        ax=ax
    )

fig.tight_layout()

data_subset_for_grid = data.loc[idx_subset]

g = sns.PairGrid(data_subset_for_grid)
g.map(sns.scatterplot)

"""### Препроцессинг"""

dups = data.duplicated(subset=feature_columns)

dups.shape

data = data[~dups]

data.shape

X = data.loc[:, feature_columns]
Y = data.loc[:, target_columns]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, shuffle=1, random_state=42)

X_train.shape, Y_train.shape

X_test.shape, Y_test.shape

X_train.head()

scaler = MinMaxScaler(feature_range=(-1, 1))
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

X_train

"""### Обучение сети"""
def losesss(y_true, y_pred):
    print('X')
    print(y_true)
    print('Y')
    print(y_pred)
    return 10

def get_model(n_inputs, n_outputs, learning_rate, hidden_layer_count):
    """
    n_inputs - количество входов
    n_outputs - количество выходов
    learning_rate - скорость обучения
    hidden_layer_count - количество нейронов скрытого слоя
    """
    model = Sequential([
        Dense(20, input_dim=n_inputs, kernel_initializer="he_uniform", activation="relu"),
        Dense(hidden_layer_count, activation="relu"),
        Dense(n_outputs, activation="relu"),
    ])
    model.compile(
        optimizer=tf.optimizers.Adam(
            learning_rate=learning_rate,
            beta_1=0.9,
            beta_2=0.999,
            epsilon=1e-07,
            amsgrad=False,
            name="Adam"
        ),
        loss=losesss,
        metrics=["accuracy"],
    )
    return model

def train(learning_rate, epochs, hidden_layer_count, verbose=1):
    """
    learning_rate - скорость обучения
    epochs - количество итераций
    hidden_layer_count - количество нейронов скрытого слоя
    """
    # Build the model
    model = get_model(n_inputs=len(feature_columns), n_outputs=len(target_columns),
                      learning_rate=learning_rate, hidden_layer_count=hidden_layer_count)

    # Train the model
    history = model.fit(
        x=X_train,
        y=Y_train,
        epochs=epochs,
        verbose=verbose,
        validation_data=(X_test, Y_test)
    )

    loss = history.history["loss"][-1]
    accuracy = history.history["accuracy"][-1]

    if verbose == 0:
        print(f"loss: {loss} - accuracy: {accuracy}")

    return model, history, accuracy, loss

model, history, base_accuracy, base_loss = train(learning_rate=0.001, epochs=50, hidden_layer_count=32)

model.summary()

plot_model(model, show_shapes=True, show_layer_names=True)

base_accuracy

# Save the model to disk
# base_model.save_weights("model.h5")

# Load the model from disk later using:
# base_model.load_weights("model.h5")

# Evaluate the model
model.evaluate(
    X_test,
    Y_test
)

# Predict on the first 5 tests
predictions = model.predict(X_test[:5])

# Print our model's predictions
print(predictions)

# Check our predictions against the ground truths
print(Y_test[:5])

Y_pred = model.predict(X_test)

training_loss = history.history["loss"]
test_loss = history.history["val_loss"]

# Get training and test accuracy histories
training_acc = history.history["accuracy"]
test_acc = history.history["val_accuracy"]

# Create count of the number of epochs
epoch_count = range(1, len(training_loss) + 1)

# Visualize loss history
plt.figure()
plt.title("Loss")
plt.plot(epoch_count, training_loss)
plt.plot(epoch_count, test_loss)
plt.legend(["Train", "Test"])
plt.xlabel("Epoch")
plt.ylabel("Loss value")
plt.show()

# Visualize accuracy history
plt.figure()
plt.title("Acuracy")
plt.plot(epoch_count, training_acc)
plt.plot(epoch_count, test_acc)
plt.legend(["Train", "Test"])
plt.xlabel("Epoch")
plt.ylabel("Accuracy value")
plt.show()

